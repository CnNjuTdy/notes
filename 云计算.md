#### 课程介绍

这门课是任桐炜老师和李传艺老师一起上的这门课

这门课是一门D类课，如果你觉得它不好玩，就可以直接走了，课件会在moudle上公布。

今年的课程是第一学期，课程内容依然是课堂讲授和课程实践

两个班上课的问题是课时数会不一样，所以今年的变化在于课程实践很多

满足下面条件的学生不要选这门课：

- 已经对云计算认知有较多理解，希望加深认识
  - 这是一门导学课程，讲授基本概念和基本操作
- 已经有发展方向，并且与云计算无关
- 想简单听课拿分走人
  - 有很多课程时间，还有期末考试（闭卷）

研究生学习的目标是创造力是研究生阶段的关键

教学目标包括

- 掌握云计算的基本概念
- 熟悉云计算挂件技术的原理
- 完成基于Spark平台的云计算实践
- 培养阅读，写作和报告的能力

参考资料

- 云计算  刘鹏（广而浅）
- 大数据：互联网大规模数据挖掘与分布式处理  王斌（深）
- Spark 最佳实践 陈欢（实践）
- 深入理解大数据  黄宜华（源码好复现）

课程计划

- 上10次课，课程讲授6次，实践讨论4次
- 期末考试：12月1日（暂定）
- 平时实践60分，期末考试40分
- 平时实践是个人作业：并且所有实践后才能得分

#### 绪论

耳熟能详的概念：物联网，大数据，云计算，人工智能等

计算机系统与人类生活的演进是很相似的

- 人类刚开始是个体，每个人都需要有技能--->人类开始聚集，逐渐分工（狩猎，采集，手工），形成部落--->部落聚集称为城邦，并且有一些共享的基础设施（水井，城墙），并且能够做出各种交换，社会分工变得精细--->社会高度发达和分工，社会资源调度动态化
- 计算机刚开始也是所有数据和应用都存储在本机上，只能给自己用—>计算机也开始分工，有的专门做存储，有的专门做计算，有的专门做服务，形成局域网--->局域网聚集形成互联网，共享的网路，共享的基础资源不属于任何个体计算机，形成大量的网络服务和信息共享—>计算机系统应该怎么做？

计算机系统需要更加先进的基础设施，更加动态的资源规划，形成云计算。

- 输入：大数据

- 算法：人工智能

- 硬件平台：云计算  类脑计算

- 输出：互联网+  物联网

什么是云：支撑各种各样网络应用的硬件平台

- 谷歌创业初期用二手的pc组装服务器：小鱼群吃大鱼
- 亚马逊之前出现的问题是，节假日高峰期需要好多服务器，但是平时在落灰，所以弹性出租资源：将计算资源变成易用的水和电，挥之即来，挥之即去

云计算是一种**商业**计算模型，它将计算任务分布在**大量**计算机构的资源池上，使**各种应用系统**能够**根据需要**获取计算力，存储空间和信息服务。

> 这是一个从商业界产生的技术，并不是实验室出来的。工业届产生了这个技术，但是有些不完善的地方，然后才有学校或者科研界来进行完善。
>
> 兵无常势，水无常形

云计算的服务类型

- （通用）IaaS：硬件资源服务化，裸机，需要解决的主要问题是怎么把数个计算机在逻辑上合并成一个整体
- PaaS：平台资源服务化，有着一些基本的功能，例如邮件功能，操作系统
- （专用）SaaS：应用资源服务化，十分专用，例如邮件服务器，上面只有邮件应用

> 误区：PaaS并不一定要调用IaaS，这个并不是一定要一层层调用的，PaaS可以直接调用计算机资源，也可以把硬件资源看成一个整体，调用IaaS，SaaS也一样

用户对象

- 公有云：大规模多用户设计
- 混合云：混合使用公有云和私有云的服务（鸡尾酒一样，一层私有云，另一层公有云）
- 私有云：在数据中心的专用机器上运行

云计算的优势

- 可扩展性和伸缩性：连接多台计算机以达到很高的计算性能，快速性能伸缩以节省成本
  - 内存万GB以上
  - 硬盘没有上限
  - 快速完成配置
  - 短时间内的费用很便宜
- 易用性
  - 虚拟化：模拟很多用户的不同功能
  - 高可靠：多副本容错
  - 管理简单：不需要专门的人员来维护
  - 安全：专业的团队和严格的权限管理
- 经济性
  - 更低的硬件成本：硬件成本，电价，成本费用
  - 更高的利用率

为什么需要自己的云平台

- 数据安全：政府，企业高度重视
- 经济效益：降低企业成本，提供创业机会

云计算难在哪里

- 多机器协作
- 容灾：机器坏了怎么办
- 异构：机器性能不一致
- 动态环境的不稳定性

#### 商业云平台

云计算起源于商业需求，并在商业中得到广泛应用

商业云平台的技术大部分都不公开

代表性的商业平台：谷歌，亚马逊，微软，阿里巴巴

谷歌云平台

> 浏览器=操作系统

- 海量用户，海量数据，需要较强的可伸缩性

- 原本设想：应用，数据，计算能力和存储空间都向互联网迁移

- 谷歌云计算平台的技术架构

  - 文件存储：GFS
    - 将文件划分为固定大小的块（chunk）存储
    - 通过冗余来提高可靠性
    - 通过“单个”master来协调数据访问和元数据存储
    - 无缓存
  - 并行数据处理：Map-Reduce
    - 数据的映射与规约
  - 结构化数据存储：BigTable
    - 切割表以解决稀疏表的问题：表--->子表--->SSTable文件
    - 对表的修改完全以增量形式来改，即保存不同时期的数据
  - 分布式锁：Chubby
    - 选举主服务器，解决主控节点负载量太大的问题：当主服务器出现问题时，一方面给出宽限期，一方面不停询问主服务器
    - 与服务器通过远程过程调用连接，每个应用有一个Chubby程序库

亚马逊云平台

>提供多种服务

- 简单存储服务，通过接口将任何类型的数据临时或者永久的存在服务器（基于Dynamo架构）s3
  - 存储架构：桶（相当于文件夹，服务器名全局唯一），对象（相当于文件，每个桶唯一，不能重命名对象，不能部分修改对象）
  - 冗余架构：最终一致性模型，牺牲一致性，保证可用性和可靠性，在全部更新之前，会返回之前的结果。例如你新写了一个对象之后，可能读的到（访问了刚刚的那个服务器），也有可能读不到（访问了其他服务器）
- 计算服务ec2
  - 会附带一个Amazon Mechine Image（AMI）：类似于操作系统，分为共有，私有，付费，共享这几种
  - 实例：类似于主机，提供计算能力
  - EBS，弹性块存储：可以一直保存直到删除
  - 通信地址
    - 共有ip：外界访问
    - 私有ip：内部实例访问
- 简单数据库服务SimpleDB（几乎已经不用了）
  - 用来存储结构化数据，简单
  - 和s3相比：s3存大量非结构化数据
  - 和关系数据库相比：并不是表结构，是树状结构
    - 域：类比一个表，不允许域间查询
    - 条目：域内是唯一的，类似于行，不需要事先定义模式
    - 属性：条目的特征
    - 值：允许多值属性，可以用指针指向s3中较大的数据
  - 采用最终一致性模型
- 队列服务SQS
  - 解决低耦合系统的通信问题
  - 队列是存放消息的队列
  - 消息是一定格式的文本，它会被冗余存储，采用加权随机分布的消息取样

微软Azure云平台

> 对企业的掌握很深入。被迫加入云服务

- 云+端（即网络+本地）是将来的倾向
- 软件+服务（SS）战略
- 计算服务：支持大量并行用户的应用程序
- 存储服务：Blob(s3),Table(SimpleDB),Queue(SQS)
- 数据库服务：SQL Server分布式化

阿里云平台（模仿了谷歌的架构）

- 阿里巴巴开发数据处理服务
  - 淘宝，余额宝，蚂蚁金服等
  - 10年前：存储昂贵，数据孤岛，重复拷贝
  - 09年成立阿里云，10年自主研发平台开始运行，12年建立统一数据平台，13年具备超大海量数据处理能力，14年大数据平台日趋成熟，15年对外输出
- 分布式文件系统（盘古）
  - Master/Salve架构
  - 稳定，多租户，高性能，大规模
- 资源管理与任务调度（伏羲）
- ODPS：海量数据存储，丰富的计算工具和编程模型

> 云平台还是要和本地端结合起来使用

#### 开源云平台

Hadoop

- Apache支持，JAVA语言，参考google
- 谷歌四大件

  - HDFS：GFS
  - Hadoop MapReduce：MapReduce
  - HBase ：BigTable
  - ZooKeeper ：Chubby
- HDFS设计目标和前提

  - 部署在廉价硬件上，能够高容错，可靠存储海量数据
  - 流式访问，大规模数据集，简单一致性模型，允许移动计算，硬件错误是常态
- MapReduce计算流程

  - 存储和计算用的类似（同样）的架构
  - JobTracker负责调度和管理TaskTracker      
  - 计算和存储共享节点，和存储在物理上用的同一套机器
  - 缺陷：单点故障，内存开销等等
- HBase

  - 空间的扩展只需要加入存储节点

  - 实现极大的，稀疏的表

    - 把大的，稀疏的表切分成子表，划分出的叫做区域
    - 每个区域含有一个随机id，区域内的行按照行键排序
    - 当表大小超过阈值的时候，自动分割成两个区域

  - 不支持SQL
- Zookeeper
  - 设计目标：大部分分布式应用需要一个主控、协调器或控制器来管理物理分布的子进程（资源，任务分配）


> 这一块和前天晚上讲得一样，大数据课上的讲得一样的
>
> 移动计算比移动数据更合算：在wordcount实验里面，绝大部分时间都花在了移动数据上，因此尽量在数据产生的地方进行计算。

Eucalyptus：模块化，java，对应亚马逊云服务

OpenStack：为公共及私有云的建设与管理提供软件

MongoDB：构建基于分布式文件存储系统的数据库

Cassandra：可扩展且无单点故障的键值存储系统

#### MapReduce

设计要求：处理对象要多，而且类别要多，结构化和非结构化读要有

应用需求：有效管理和高效分析

设计目标

- 海量数据
- 多cpu
- 比较容易的实现以上目标

基本思想是分而治之

计算流程

- 遍历大规模记录
- 从每个记录中抽取中间结果（Map）
- 排序中间结果
- 中间结果集成（Reduce）
- 生成最终结果

map函数：`map(key,value)->(key,value)list`

reduce函数：`reduce(key,valuelist)->value list`

#### 闲话

- 为什么要在云计算的课堂上讲大数据的概念？

云计算课程分为两个部分，第一部分是云计算概述和基本原理，第二部分是基于云计算平台的大数据处理实践，说到底还是你们大数据的课程。这门课的基础是应用系统的介绍，核心是开发实践，目标是数据驱动的创新的体验，理想是有趣，有价值的业务逻辑。

- 2017年作业回顾-实践作业1
  - 第一阶段是数据爬取和存储到MongoDB
  - 第二阶段是流数据处理和结果展示
  - 选题范围包括京东商品评论，股票网站评论，阿里商品的数据集，豆瓣用户小组信息
- 2017年作业回顾-时间作业2
  - 第一阶段是构造图和展示图
  - 第二阶段是基于图的操作方法进行计算
  - 选题范围和第一个一样
- 基于spark的机器学习实践
  - 提出一个分类或者聚类的问题
  - 整理训练集和测试集
  - 使用mllib工具训练分类器
  - 汇报结果
- 今年的改变
  - 独立完成作业
  - 增加作业量
    - 小作业和实践作业
  - 作业用python
    - 小作业自动检查
    - 实践作业代码自动分析
  - 小作业
    - python topk算法
    - 基于spark的MapReduce实现topk算法
    - spark streaming实现topk算法
    - spark graphx热身
    - 检查点：按时提交，语法正确，用例通过
  - 实践作业
    - streaming
    - graphx
    - mllib
    - 检查点：按时提交，语法正确，汇报
    - 强调数据的多元化
  - 实践作业一定要汇报
    - 按照提交顺序汇报

#### spark

为了处理大规模数据的通用快速计算引擎。

分布式计算：计算资源管理

并行计算：任务的管理与分级

##### spark 简介

概览：快，易用，功能强（sql，streaming，graphx，mllib），更加通用（使用多种集群管理框架，使用多种数据存储方式）

- 功能

Spark SQL：用于处理结构化数据的分布式计算引擎

Spark Streaming：实时对大量数据进行快速处理，处理周期短

Spark GraphX：以图为基础的数据结构的算法实现和应用

Spark MLlib：位解决机器学习开发的库

- 集群管理框架

Standalone mode：原生集群管理功能，任务调度，资源分配等

Apache Mesos：从分布式计算节点上抽象资源给其他框架使用，实现了静态资源分配功能

Hadoop Yarn：Hadoop MapReduce的第二个版本架构

EC2：AmazonEC2云平台

- 存储方式

HDFS，Hbase，MongoDB，Cassendra

- MapReduce

最早起源于函数式变成，重点是编写Map和Reduce函数，其中Map函数负责过滤和采集数据，Reduce函数负责规约数据得到结果。

什么时候不使用？一个值的计算依赖前一个值，数据集合小，需要同步，一个操作依赖另一个操作，处理器敏感操作，这些情况不适用。

Hadoop是开源的MapReduce应用框架，适合单趟计算，如果多趟效率会比较慢。

Spark不是一个专门的MapReduce框架，但是支持MapReduce的功能。它不限于先map再reduce。

##### 目标

1. 系统搭建：Spark Standalone + HDFS + MongoDB
2. 利用spark处理数据

##### Spark原理

1. Spark提交应用程序
2. Driver程序：应用执行的起点
3. SparkContext对象：使得应用程序能够和集群进行沟通
4. 其他关键名词：application，master，executor，job，stage，task
5. 具体执行过程
   1. SparkContext向Master注册并申请资源
   2. Master分配并监控资源给workers
   3. works向context注册并发送信条
   4. context分配任务，发送代码
   5. 执行完成之后context向master申请注销

##### 核心数据结构：RDD

- 分区列表:记录了数据块所在的分区位置;一个RDD对应的数据是切分 为数据块存储在集群的不同节点上的
- 依赖列表:记录了当前这个RDD依赖于哪些其它的RDD 
- 计算函数compute，用于计算RDD各个分区的值 
- 可选:分区器，子类可以重新指定新的分区方式
- 可选:计算各分区时优先的位置列表 

